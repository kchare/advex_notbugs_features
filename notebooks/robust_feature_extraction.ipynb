{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730cd502",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- https://adversarial-ml-tutorial.org/adversarial_examples/\n",
    "- https://arxiv.org/pdf/1905.02175.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ad2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a307b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img, label):\n",
    "    return img / 255, label\n",
    "\n",
    "def make_tf_data(raw_ds):\n",
    "    ds = raw_ds.map(normalize)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97201c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(n_layers, n_filters, kernel_size=3, n_classes=10, model_name='basic_cnn'):\n",
    "    \"\"\"Builds basic CNN model for adversarial training; will need to be refactored\n",
    "    non-using default train setup\"\"\"\n",
    "    input_layer = tf.keras.layers.Input(shape=(28,28,1))\n",
    "    \n",
    "    # Add basic convolutional_layer\n",
    "    hidden = tf.keras.layers.Conv2D(n_filters, kernel_size=3, strides=2, activation = 'relu')(input_layer)\n",
    "    # Add single dense, non-linear layer\n",
    "    hidden = tf.keras.layers.Flatten()(hidden)\n",
    "    hidden = tf.keras.layers.Dense(16, activation = 'relu')(hidden)\n",
    "    output = tf.keras.layers.Dense(n_classes, activation='softmax')(hidden) # softmax since multiclass class. problem\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c481223",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tfds.load('mnist', split='train', shuffle_files=True, as_supervised=True, batch_size=32)\n",
    "test_ds = tfds.load('mnist', split='test', shuffle_files=True, as_supervised=True, batch_size=32)\n",
    "\n",
    "train_ds = make_tf_data(train_ds)\n",
    "test_ds = make_tf_data(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e79c0",
   "metadata": {},
   "source": [
    "### Train robust model resistant to FGSM attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "953b8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def fgsm_attack(model, X, y, epsilon=0.1):\n",
    "    delta = tf.zeros_like(X)\n",
    "    \n",
    "    # use GradientTape to perform autodiff\n",
    "    with tf.GradientTape() as tape:\n",
    "        # specifically 'watch' delta\n",
    "        # see here: https://www.tensorflow.org/guide/autodiff\n",
    "        tape.watch(delta)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy()(y, model(X + delta))\n",
    "    delta = tf.sign(tape.gradient(loss, delta)) * epsilon\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34190931",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def onestep_pgd_linf(model, X, y, epsilon, alpha, delta):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(delta)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy()(y, model(X + delta))\n",
    "\n",
    "    delta = tf.clip_by_value(delta + alpha*tf.sign(tape.gradient(loss, delta)), -epsilon, epsilon)\n",
    "    \n",
    "    return delta\n",
    "\n",
    "def pgd_linf(model, X, y, epsilon, alpha, num_iter):\n",
    "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
    "    delta = tf.zeros_like(X)\n",
    "    for t in range(num_iter):\n",
    "        delta = onestep_pgd_linf(model, X, y, epsilon, alpha, delta)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "500e900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(Z):\n",
    "    \"\"\"Compute norms over all but the first dimension\"\"\"\n",
    "    return tf.norm(Z[0,:,:,:])\n",
    "\n",
    "# PGD L2 for Robustifying #\n",
    "def single_pgd_step_robust(model, X, y, alpha, delta):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(delta)\n",
    "        loss = tf.keras.losses.MeanSquaredError()(y, model(X + delta)) # comparing to robust model representation layer\n",
    "        print(loss.as_numpy_iterator()[0])\n",
    "        \n",
    "    grad = tape.gradient(loss, delta)\n",
    "    delta -= alpha*grad / norm(grad) # normalized gradient step\n",
    "    delta = tf.math.minimum(tf.math.maximum(delta, -X), 1-X) # clip X+delta to [0,1]\n",
    "    \n",
    "    return delta, loss\n",
    "\n",
    "@tf.function\n",
    "def pgd_l2_robust(model, X, y, alpha, num_iter, bounded=False, epsilon=0, example=False):\n",
    "    delta = tf.zeros_like(X)\n",
    "    loss = 0\n",
    "    for t in range(num_iter):\n",
    "        delta, loss = single_pgd_step_robust(model, X, y, alpha, delta)\n",
    "        if bounded:\n",
    "            delta *= epsilon / tf.clip_by_value(norm(delta), epsilon, np.inf)\n",
    "            # No epsilon bound here\n",
    "    #         delta.data *= epsilon / norms(delta.detach()).clamp(min=epsilon) \n",
    "            # I think tensorflow does this automatically\n",
    "#             delta.grad.zero_()\n",
    "\n",
    "    if example:\n",
    "        print(f'{num_iter} iterations, final MSE {loss}')\n",
    "    return delta\n",
    "\n",
    "# PGD L2 for Adversarial Examples #\n",
    "def single_pgd_step_adv(model, X, y, alpha, epsilon, delta):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(delta)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy()(y, model(X + delta)) # comparing to label for original data point\n",
    "\n",
    "    grad = tape.gradient(loss, delta)\n",
    "    delta -= alpha*grad / norm(grad) # normalized gradient step\n",
    "    delta = tf.math.minimum(tf.math.maximum(delta, -X), 1-X) # clip X+delta to [0,1]\n",
    "    delta *= epsilon / tf.clip_by_value(norm(delta), epsilon, np.inf)\n",
    "    \n",
    "    return delta, loss\n",
    "\n",
    "@tf.function\n",
    "def pgd_l2_adv(model, X, y, alpha, num_iter, epsilon=0, example=False):\n",
    "    delta = tf.zeros_like(X)\n",
    "    loss = 0\n",
    "    for t in range(num_iter):\n",
    "        delta, loss = single_pgd_step_adv(model, X, y, alpha, epsilon, delta)\n",
    "        \n",
    "    if example:\n",
    "        print(f'{num_iter} iterations, final MSE {loss}')\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b277046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 13:06:40.079718: W tensorflow/core/kernels/data/cache_dataset_ops.cc:798] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f84598cce10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model = build_cnn_model(1, 32)\n",
    "for b in train_ds.unbatch():\n",
    "    X, y = b\n",
    "    X = tf.expand_dims(X, 0)\n",
    "    delta = fgsm_attack(test_model, X, y, 0.02)\n",
    "    Xd = X + delta\n",
    "    break\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].imshow(np.squeeze(X))\n",
    "axs[1].imshow(np.squeeze(Xd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71ac873b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f845c3c1ad0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model = build_cnn_model(1, 32)\n",
    "for b in train_ds.unbatch():\n",
    "    X, y = b\n",
    "    X = tf.expand_dims(X, 0)\n",
    "    delta = pgd_l2_adv(test_model, X, y, epsilon=0.5, alpha=0.1, num_iter=1000)\n",
    "#     delta = pgd_linf(test_model, X, y, epsilon=0.1, alpha=1e-2, num_iter=50)\n",
    "\n",
    "    Xd = X + delta\n",
    "    break\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].imshow(np.squeeze(X))\n",
    "axs[1].imshow(np.squeeze(Xd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d06351",
   "metadata": {},
   "source": [
    "## Standard training with adversary in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a013ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5, Time: 160.86 -- Train Loss: 0.30, Train Acc: 0.92, Test Loss: 0.07, Test Acc: 0.99\n",
      "Epoch 1/5, Time: 118.27 -- Train Loss: 0.11, Train Acc: 0.97, Test Loss: 0.06, Test Acc: 0.99\n",
      "Epoch 2/5, Time: 116.40 -- Train Loss: 0.08, Train Acc: 0.98, Test Loss: 0.09, Test Acc: 0.99\n",
      "Epoch 3/5, Time: 108.44 -- Train Loss: 0.06, Train Acc: 0.98, Test Loss: 0.06, Test Acc: 0.99\n",
      "Epoch 4/5, Time: 105.22 -- Train Loss: 0.05, Train Acc: 0.99, Test Loss: 0.11, Test Acc: 0.99\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "# Build model again, leaving out summary\n",
    "model = build_cnn_model(1, 32)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "for n in range(EPOCHS):\n",
    "    \n",
    "    t = time.time()\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    for b in train_ds:\n",
    "        X, y = b\n",
    "\n",
    "        l, acc = model.train_on_batch(X, y)\n",
    "        train_losses.append(l)\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    for vb in test_ds:\n",
    "        Xtest, ytest = vb\n",
    "        \n",
    "        # Apply attack to get delta\n",
    "        # Importantly, only attack at test time rather than during training\n",
    "#         delta = fgsm_attack(model, Xtest, ytest)\n",
    "#         delta = pgd_linf(model, Xtest, ytest, epsilon=0.1, alpha=1e-1, num_iter=40)\n",
    "        delta = pgd_l2_adv(model, Xtest, ytest, epsilon=0.5, alpha=0.1, num_iter=500)\n",
    "        Xdtest = Xtest + delta\n",
    "        \n",
    "        l, acc = model.test_on_batch(Xdtest, ytest)\n",
    "        test_losses.append(l)\n",
    "        test_accs.append(acc)\n",
    "    \n",
    "    train_loss = sum(train_losses) / len(train_losses)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    \n",
    "    test_loss = sum(test_losses) / len(test_losses)\n",
    "    test_acc = sum(test_accs) / len(test_accs)\n",
    "        \n",
    "    print(f\"Epoch {n}/{EPOCHS}, Time: {(time.time()-t):0.2f} -- Train Loss: {train_loss:0.2f}, \\\n",
    "Train Acc: {train_acc:0.2f}, Test Loss: {test_loss:0.2f}, Test Acc: {test_acc:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c5aae",
   "metadata": {},
   "source": [
    "## Train Robust Model (adversaries in training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f4071b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5, Time: 83.58 -- Train Loss: 0.06, Train Acc: 0.99, Test Loss: 0.36, Test Acc: 0.89\n",
      "Epoch 1/5, Time: 68.66 -- Train Loss: 0.00, Train Acc: 1.00, Test Loss: 0.48, Test Acc: 0.85\n",
      "Epoch 2/5, Time: 68.04 -- Train Loss: 0.00, Train Acc: 1.00, Test Loss: 0.36, Test Acc: 0.89\n",
      "Epoch 3/5, Time: 64.31 -- Train Loss: 0.00, Train Acc: 1.00, Test Loss: 0.91, Test Acc: 0.74\n",
      "Epoch 4/5, Time: 64.35 -- Train Loss: 0.00, Train Acc: 1.00, Test Loss: 0.42, Test Acc: 0.87\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "# Build model again, leaving out summary\n",
    "robust_model = build_cnn_model(1, 32)\n",
    "\n",
    "robust_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "for n in range(EPOCHS):\n",
    "    t = time.time()\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    for b in train_ds:\n",
    "        X, y = b\n",
    "        \n",
    "        # Apply attack during training as well as testing\n",
    "#         delta = fgsm_attack(robust_model, X, y, 0.02)\n",
    "        delta = pgd_l2_adv(robust_model, X, y, epsilon=0.5, alpha=1e-1, num_iter=50)\n",
    "#         delta = pgd_linf(robust_model, X, y, epsilon=0.1, alpha=1e-1, num_iter=40)\n",
    "        Xd = X + delta\n",
    "\n",
    "        l, acc = robust_model.train_on_batch(Xd, y)\n",
    "        train_losses.append(l)\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    for vb in test_ds:\n",
    "        Xtest, ytest = vb\n",
    "        \n",
    "        # Apply attack to get delta\n",
    "        # Importantly, only attack at test time rather than during training\n",
    "        #delta = fgsm_attack(model, Xtest, ytest)\n",
    "        Xdtest = Xtest #+ delta\n",
    "        \n",
    "        l, acc = robust_model.test_on_batch(Xdtest, ytest)\n",
    "        test_losses.append(l)\n",
    "        test_accs.append(acc)\n",
    "    \n",
    "    train_loss = sum(train_losses) / len(train_losses)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    \n",
    "    test_loss = sum(test_losses) / len(test_losses)\n",
    "    test_acc = sum(test_accs) / len(test_accs)\n",
    "        \n",
    "    print(f\"Epoch {n}/{EPOCHS}, Time: {(time.time()-t):0.2f} -- Train Loss: {train_loss:0.2f}, \\\n",
    "Train Acc: {train_acc:0.2f}, Test Loss: {test_loss:0.2f}, Test Acc: {test_acc:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b2c7b",
   "metadata": {},
   "source": [
    "## Generate robust version of original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff02734",
   "metadata": {},
   "source": [
    "Use robust NN to create a robustifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ec23269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab representation layer from robust model\n",
    "representation = robust_model.layers[-2]\n",
    "robustifier = tf.keras.Model(inputs = robust_model.input, outputs = representation.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddff9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "unbatched_train = train_ds.unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f48232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_img = list(unbatched_train.as_numpy_iterator())[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50690ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robustified 0 images in 0.057 seconds\n",
      "Robustified 1000 images in 9.212 seconds\n",
      "Robustified 2000 images in 9.359 seconds\n",
      "Robustified 3000 images in 10.028 seconds\n",
      "Robustified 4000 images in 9.504 seconds\n",
      "Robustified 5000 images in 9.174 seconds\n",
      "Robustified 6000 images in 10.705 seconds\n",
      "Robustified 7000 images in 11.300 seconds\n",
      "Robustified 8000 images in 10.568 seconds\n",
      "Robustified 9000 images in 9.888 seconds\n",
      "Robustified 10000 images in 10.441 seconds\n",
      "Robustified 11000 images in 10.269 seconds\n",
      "Robustified 12000 images in 11.034 seconds\n",
      "Robustified 13000 images in 9.824 seconds\n",
      "Robustified 14000 images in 10.287 seconds\n",
      "Robustified 15000 images in 9.551 seconds\n",
      "Robustified 16000 images in 9.054 seconds\n",
      "Robustified 17000 images in 9.037 seconds\n",
      "Robustified 18000 images in 9.870 seconds\n",
      "Robustified 19000 images in 11.464 seconds\n",
      "Robustified 20000 images in 9.718 seconds\n",
      "Robustified 21000 images in 9.795 seconds\n",
      "Robustified 22000 images in 9.360 seconds\n",
      "Robustified 23000 images in 9.127 seconds\n",
      "Robustified 24000 images in 8.962 seconds\n",
      "Robustified 25000 images in 9.723 seconds\n",
      "Robustified 26000 images in 9.410 seconds\n",
      "Robustified 27000 images in 9.377 seconds\n",
      "Robustified 28000 images in 9.984 seconds\n",
      "Robustified 29000 images in 10.340 seconds\n",
      "Robustified 30000 images in 9.773 seconds\n",
      "Robustified 31000 images in 9.909 seconds\n",
      "Robustified 32000 images in 10.287 seconds\n",
      "Robustified 33000 images in 9.304 seconds\n",
      "Robustified 34000 images in 12.195 seconds\n",
      "Robustified 35000 images in 11.102 seconds\n",
      "Robustified 36000 images in 11.439 seconds\n",
      "Robustified 37000 images in 8.659 seconds\n",
      "Robustified 38000 images in 8.990 seconds\n",
      "Robustified 39000 images in 10.652 seconds\n",
      "Robustified 40000 images in 9.969 seconds\n",
      "Robustified 41000 images in 8.974 seconds\n",
      "Robustified 42000 images in 9.060 seconds\n",
      "Robustified 43000 images in 9.199 seconds\n",
      "Robustified 44000 images in 10.461 seconds\n",
      "Robustified 45000 images in 9.294 seconds\n",
      "Robustified 46000 images in 8.758 seconds\n",
      "Robustified 47000 images in 8.813 seconds\n",
      "Robustified 48000 images in 8.731 seconds\n",
      "Robustified 49000 images in 8.795 seconds\n",
      "Robustified 50000 images in 8.759 seconds\n",
      "Robustified 51000 images in 8.761 seconds\n",
      "Robustified 52000 images in 8.713 seconds\n",
      "Robustified 53000 images in 8.861 seconds\n",
      "Robustified 54000 images in 8.794 seconds\n",
      "Robustified 55000 images in 8.761 seconds\n",
      "Robustified 56000 images in 8.950 seconds\n",
      "Robustified 57000 images in 8.801 seconds\n",
      "Robustified 58000 images in 8.667 seconds\n",
      "Robustified 59000 images in 9.935 seconds\n"
     ]
    }
   ],
   "source": [
    "robust_train = []\n",
    "orig_labels = []\n",
    "iters = 100\n",
    "example = False\n",
    "# initialize random image as last image in dataset\n",
    "rand_img = last_img\n",
    "rand_img = tf.expand_dims(rand_img, axis=0)\n",
    "\n",
    "start_time = time.time()\n",
    "for i, (img, label) in enumerate(unbatched_train):\n",
    "    # data point we want to get robust features for\n",
    "    curr_img = tf.expand_dims(img, axis=0)\n",
    "    goal_representation = robustifier(curr_img)\n",
    "    \n",
    "    \n",
    "    learned_delta = pgd_l2_robust(robustifier, rand_img, goal_representation, alpha=0.1, num_iter=iters)\n",
    "    robust_update = (rand_img + learned_delta)[0,:,:,:] # trim off first dim\n",
    "    robust_train.append(robust_update)\n",
    "    orig_labels.append(label)\n",
    "    \n",
    "    if i%1000 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f'Robustified {i} images in {elapsed:0.3f} seconds')\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # reset random image to be previous image\n",
    "    rand_img = curr_img.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee4b3b",
   "metadata": {},
   "source": [
    "### Aside to see adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = True\n",
    "for img, label in unbatched_train:\n",
    "    # data point we want to get robust features for\n",
    "    curr_img = tf.expand_dims(img, axis=0)\n",
    "    goal_representation = robustifier(curr_img)\n",
    "    \n",
    "    # starting point for PGD is another point in the dataset\n",
    "    rand_img = next(unbatched_train.shuffle(int(1e6)).take(1).as_numpy_iterator())[0]\n",
    "    rand_img = tf.expand_dims(rand_img, axis=0)\n",
    "    \n",
    "    fig, starts = plt.subplots(1,2,figsize=(5,5))\n",
    "    starts = starts.flatten()\n",
    "    starts[0].imshow(rand_img[0,:,:,:].numpy())\n",
    "    starts[0].set_title('Random Initialization')\n",
    "    starts[1].imshow(curr_img[0,:,:,:])\n",
    "    starts[1].set_title('Target Image')\n",
    "    \n",
    "    fig, axs = plt.subplots(5, 2, figsize=(20,20))\n",
    "    for i, iters in enumerate([1,2,50,100,1000]):\n",
    "        learned_delta = pgd_l2_robust(robustifier, rand_img, goal_representation, alpha=0.1, num_iter=iters, example=True)\n",
    "        robust_update = (rand_img + learned_delta)[0,:,:,:] # trim off first dim\n",
    "    \n",
    "        axs[i][0].imshow(robust_update)\n",
    "        axs[i][0].set_title(f'Updated Image (iters={iters})')\n",
    "        axs[i][1].imshow(learned_delta[0,:,:,:])\n",
    "        axs[i][1].set_title(f'Delta (iters={iters})')\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f133883",
   "metadata": {},
   "source": [
    "## Try training on robust data set and testing with adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f076f339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_labels[-10].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5dd07a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc899848f10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(robust_train[-10].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2568d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_ds = tf.data.Dataset.from_tensor_slices((robust_train, orig_labels)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40d723f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5, Time: 22.51 -- Train Loss: 1.01, Train Acc: 0.67, Test Loss: 0.36, Test Acc: 0.96\n",
      "Epoch 1/5, Time: 19.24 -- Train Loss: 0.63, Train Acc: 0.81, Test Loss: 0.19, Test Acc: 0.99\n",
      "Epoch 2/5, Time: 18.97 -- Train Loss: 0.53, Train Acc: 0.84, Test Loss: 0.12, Test Acc: 1.00\n",
      "Epoch 3/5, Time: 18.89 -- Train Loss: 0.49, Train Acc: 0.85, Test Loss: 0.09, Test Acc: 1.00\n",
      "Epoch 4/5, Time: 19.78 -- Train Loss: 0.46, Train Acc: 0.86, Test Loss: 0.07, Test Acc: 1.00\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "# Build model again, leaving out summary\n",
    "model = build_cnn_model(1, 32)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "for n in range(EPOCHS):\n",
    "    \n",
    "    t = time.time()\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    for b in robust_ds:\n",
    "        X, y = b\n",
    "\n",
    "        l, acc = model.train_on_batch(X, y)\n",
    "        train_losses.append(l)\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    for vb in test_ds:\n",
    "        Xtest, ytest = vb\n",
    "        \n",
    "        # Apply attack to get delta\n",
    "        # Importantly, only attack at test time rather than during training\n",
    "#         delta = fgsm_attack(model, Xtest, ytest)\n",
    "        delta = pgd_l2_adv(model, Xtest, ytest, bounded=True, epsilon=0.1, alpha=1e-2, num_iter=40)\n",
    "        Xdtest = Xtest + delta\n",
    "        \n",
    "        l, acc = model.test_on_batch(Xdtest, ytest)\n",
    "        test_losses.append(l)\n",
    "        test_accs.append(acc)\n",
    "    \n",
    "    train_loss = sum(train_losses) / len(train_losses)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    \n",
    "    test_loss = sum(test_losses) / len(test_losses)\n",
    "    test_acc = sum(test_accs) / len(test_accs)\n",
    "        \n",
    "    print(f\"Epoch {n}/{EPOCHS}, Time: {(time.time()-t):0.2f} -- Train Loss: {train_loss:0.2f}, \\\n",
    "Train Acc: {train_acc:0.2f}, Test Loss: {test_loss:0.2f}, Test Acc: {test_acc:0.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
